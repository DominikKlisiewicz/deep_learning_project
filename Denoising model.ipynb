{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "18528fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, Conv2DTranspose, BatchNormalization, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Model, load_model\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import History\n",
    "import netron"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43fb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_audio(audio, max_duration=5, sample_rate=16000):\n",
    "    \"\"\"This function take an audio and padd that audio with zeros\"\"\"\n",
    "    \n",
    "    max_length = max_duration * sample_rate\n",
    "    padding_needed = max_length - len(audio)\n",
    "    pad_left = padding_needed // 2\n",
    "    pad_right = padding_needed - pad_left\n",
    "    \n",
    "    return np.pad(audio, (pad_left, pad_right), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fec962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audio(original_audio_path, noise_audio_path, sample_rate=16000):\n",
    "    \"\"\"This function take an original audio path and noise audio path and mix it together\"\"\"\n",
    "    \n",
    "    # Load the original audio\n",
    "    original_audio, sr = librosa.load(original_audio_path, sr=sample_rate)\n",
    "    \n",
    "    #Padd original audio\n",
    "    original_audio = padd_audio(original_audio, sample_rate=sample_rate)\n",
    "    \n",
    "    # Load the noise audio\n",
    "    noise_audio, sr_noise = librosa.load(noise_audio_path, sr=sample_rate)\n",
    "    \n",
    "    # Repeat the noise audio\n",
    "    noise_audio = np.tile(noise_audio, int(np.ceil(len(original_audio) / len(noise_audio))))\n",
    "\n",
    "    # Trim the repeated noise audio to match the length of the original audio\n",
    "    noise_audio = noise_audio[:len(original_audio)]\n",
    "    \n",
    "    return original_audio + noise_audio/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66387d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_audio(original_audio_path, sample_rate=16000):\n",
    "    \"\"\"This function take an original audio path and return padded audio\"\"\"\n",
    "    \n",
    "    # Load the original audio\n",
    "    original_audio, sr = librosa.load(original_audio_path, sr=sample_rate)\n",
    "    \n",
    "    #Padd original audio\n",
    "    return padd_audio(original_audio, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bfacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000  # Sampling rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89d2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randmly chosen noise for each audio\n",
    "def combine_audio_with_noise(original_audio_dir, noise_audio_dir):\n",
    "    combination_dict = {}\n",
    "    noise_audios = os.listdir(noise_audio_dir)\n",
    "    original_audios = os.listdir(original_audio_dir)\n",
    "    \n",
    "    for original_audio in original_audios:\n",
    "        noise_audio = np.random.choice(noise_audios)\n",
    "        combination_dict[os.path.join(original_audio_dir, original_audio)] = os.path.join(noise_audio_dir, noise_audio)\n",
    "        \n",
    "    return combination_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcecf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_stft(audio, n_fft=1199, hop_length_fft=304):\n",
    "    # STFT transformation\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "\n",
    "    # Extract magnitude and phase\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    # Convert magnitude to dB\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(stftaudio_magnitude, ref=np.max)\n",
    "    \n",
    "    return stftaudio_magnitude_db, stftaudio_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "08cda225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_audio(stftaudio_magnitude_db, stftaudio_phase, hop_length_fft=304):\n",
    "# Convert dB back to amplitude\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # Reconstruct the STFT complex matrix\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "\n",
    "    # Inverse STFT to get back the audio signal\n",
    "    audio_reconstruct = librosa.istft(audio_reverse_stft, hop_length=hop_length_fft)\n",
    "\n",
    "    return audio_reconstruct / np.max(np.abs(audio_reconstruct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "861a3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of normalization function using global min and max values\n",
    "def normalize(stft, global_min, global_max):\n",
    "    return (stft - global_min) / (global_max - global_min)\n",
    "\n",
    "# Example of denormalization function using global min and max values\n",
    "def denormalize(normalized_stft, global_min, global_max):\n",
    "    return normalized_stft * (global_max - global_min) + global_min"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e50f02cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_graphs(history, string):\n",
    "        plt.plot(history.history[string])\n",
    "        plt.plot(history.history['val_'+string])\n",
    "        plt.xlabel(\"Epochs\")\n",
    "        plt.ylabel(string)\n",
    "        plt.legend([string, 'val_'+string])\n",
    "        plt.title(string+' through epochs')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aa3d8eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_predictions(output_prediction, phase, global_min=global_min, global_max=global_max):\n",
    "    prediction = denormalize(output_prediction.squeeze(), global_min, global_max)\n",
    "    audio_prediction = stft_to_audio(prediction, phase, hop_length_fft=304)\n",
    "    return audio_prediction"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cabcf8",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "7f92181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_noise_pairs = combine_audio_with_noise(os.path.join(os.getcwd(), 'Dataset'), os.path.join(os.getcwd(), 'Noise'))\n",
    "\n",
    "#Getting all the noisy and clean audio matrices\n",
    "noisy_audios = np.zeros(len(audio_noise_pairs), dtype=object)\n",
    "clean_audios = np.zeros(len(audio_noise_pairs), dtype=object)\n",
    "\n",
    "for index, (audio_dir, noise_dir) in enumerate(audio_noise_pairs.items()):\n",
    "    noisy_audios[index] = mix_audio(audio_dir, noise_dir, sample_rate=16000)\n",
    "    clean_audios[index] = get_clean_audio(audio_dir, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1b5bbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting STFT data for learning process\n",
    "noisy_audios_stft = [audio_to_stft(audio)[0] for audio in noisy_audios]\n",
    "noisy_audios_stft_phase = [audio_to_stft(audio)[1] for audio in noisy_audios]\n",
    "clean_audios_stft = [audio_to_stft(audio)[0] for audio in clean_audios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4e2c3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training 80%, validation 10% and test set 10%\n",
    "split_ratio1 = 0.8\n",
    "split_ratio2 = 0.9\n",
    "split_index1 = int(len(noisy_audios_stft) * split_ratio1)\n",
    "split_index2 = int(len(noisy_audios_stft) * split_ratio2)\n",
    "\n",
    "X_train = noisy_audios_stft[:split_index1]\n",
    "X_val = noisy_audios_stft[split_index1:split_index2]\n",
    "X_test = noisy_audios_stft[split_index2:]\n",
    "\n",
    "y_train = clean_audios_stft[:split_index1]\n",
    "y_val = clean_audios_stft[split_index1:split_index2]\n",
    "y_test = clean_audios_stft[split_index2:]\n",
    "\n",
    "phase_train = noisy_audios_stft_phase[:split_index1]\n",
    "phase_val = noisy_audios_stft_phase[split_index1:split_index2]\n",
    "phase_test = noisy_audios_stft_phase[split_index2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "717c6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the global min and max values from both the noisy and clean STFT data\n",
    "global_min = min(np.min(X_train), np.min(y_train))\n",
    "global_max = max(np.max(X_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7bbecd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data based on the data from training set\n",
    "X_train_normalized = normalize(X_train, global_min, global_max)\n",
    "X_val_normalized = normalize(X_val, global_min, global_max)\n",
    "X_test_normalized = normalize(X_test, global_min, global_max)\n",
    "\n",
    "y_train_normalized = normalize(y_train, global_min, global_max)\n",
    "y_val_normalized = normalize(y_val, global_min, global_max)\n",
    "y_test_normalized = normalize(y_test, global_min, global_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1ba886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data to tensors: sample x dimensions(n x n) x channel(1)\n",
    "X_train_normalized = X_train_normalized[..., np.newaxis]\n",
    "X_val_normalized = X_val_normalized[..., np.newaxis]\n",
    "X_test_normalized = X_test_normalized[..., np.newaxis]\n",
    "\n",
    "y_train_normalized = y_train_normalized[..., np.newaxis]\n",
    "y_val_normalized = y_val_normalized[..., np.newaxis]\n",
    "y_test_normalized = y_test_normalized[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d148b90",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "5eb4ba4b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, y, batch_size=16, epochs=100):\n",
    "    assert len(X) == len(y), \"The length of X and y must be the same\"\n",
    "    \n",
    "    # Iterate through each epoch\n",
    "    for epoch in range(epochs):\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        \n",
    "        for start in range(0, len(X), batch_size):\n",
    "            end = min(start + batch_size, len(X))\n",
    "            batch_X = X_shuffled[start:end]\n",
    "            batch_y = y_shuffled[start:end]\n",
    "            \n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "67ecf633",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoder\n",
    "def encoder(inputs):\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    x = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    encoded = Conv2D(512, (3, 3), activation='relu', padding='same')(x)\n",
    "    return encoded\n",
    "\n",
    "# Decoder\n",
    "def decoder(encoded):\n",
    "    x = Conv2DTranspose(256, (3, 3), strides=(2, 2), activation='relu', padding='same')(encoded)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(128, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    x = Conv2DTranspose(64, (3, 3), strides=(2, 2), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    \n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)  # Single channel output\n",
    "    return decoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "80f88407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 600, 264, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_15 (Conv2D)          (None, 600, 264, 64)      640       \n",
      "                                                                 \n",
      " batch_normalization_18 (Bat  (None, 600, 264, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_9 (MaxPooling  (None, 300, 132, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_16 (Conv2D)          (None, 300, 132, 128)     73856     \n",
      "                                                                 \n",
      " batch_normalization_19 (Bat  (None, 300, 132, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_10 (MaxPoolin  (None, 150, 66, 128)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_17 (Conv2D)          (None, 150, 66, 256)      295168    \n",
      "                                                                 \n",
      " batch_normalization_20 (Bat  (None, 150, 66, 256)     1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_11 (MaxPoolin  (None, 75, 33, 256)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_18 (Conv2D)          (None, 75, 33, 512)       1180160   \n",
      "                                                                 \n",
      " conv2d_transpose_9 (Conv2DT  (None, 150, 66, 256)     1179904   \n",
      " ranspose)                                                       \n",
      "                                                                 \n",
      " batch_normalization_21 (Bat  (None, 150, 66, 256)     1024      \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_10 (Conv2D  (None, 300, 132, 128)    295040    \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_22 (Bat  (None, 300, 132, 128)    512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_transpose_11 (Conv2D  (None, 600, 264, 64)     73792     \n",
      " Transpose)                                                      \n",
      "                                                                 \n",
      " batch_normalization_23 (Bat  (None, 600, 264, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_19 (Conv2D)          (None, 600, 264, 1)       577       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 3,102,721\n",
      "Trainable params: 3,100,929\n",
      "Non-trainable params: 1,792\n",
      "_________________________________________________________________\n",
      "Epoch 1/2\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0687 \n",
      "Epoch 1: val_loss improved from inf to 0.08056, saving model to best_model.h5\n",
      "34/34 [==============================] - 521s 15s/step - loss: 0.0687 - val_loss: 0.0806 - lr: 6.2500e-04\n",
      "Epoch 2/2\n",
      "34/34 [==============================] - ETA: 0s - loss: 0.0316 \n",
      "Epoch 2: val_loss improved from 0.08056 to 0.04793, saving model to best_model.h5\n",
      "34/34 [==============================] - 542s 16s/step - loss: 0.0316 - val_loss: 0.0479 - lr: 6.2500e-04\n"
     ]
    }
   ],
   "source": [
    "#Batch size\n",
    "batch_size = 16\n",
    "\n",
    "# Input shape\n",
    "input_shape = (600, 264, 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Build the autoencoder\n",
    "encoded = encoder(inputs)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "\n",
    "# Optimizer adapts learning rate based on batch size, using Adam optimizer\n",
    "optimizer = Adam(learning_rate=0.01*(batch_size/256), beta_1=0.9, beta_2=0.999)\n",
    "\n",
    "autoencoder.compile(optimizer=optimizer, loss='mean_squared_error')\n",
    "\n",
    "# Summary of the model\n",
    "autoencoder.summary()\n",
    "\n",
    "# Initialize model checkpointing to save the model with the lowest loss.\n",
    "model_checkpoint = ModelCheckpoint('best_model.h5', monitor='val_loss', save_best_only=True, mode='min', verbose=1)\n",
    "\n",
    "# Set up early stopping to halt training if loss doesn't improve after 20 epochs.\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=20, restore_best_weights=True, mode='min', verbose=1)\n",
    "\n",
    "# Configure learning rate reduction if loss doesn't improve after 3 epochs.\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_loss', patience=3, verbose=1, factor=0.5, min_lr=0.0000001)\n",
    "\n",
    "# Fit the model\n",
    "history = autoencoder.fit(generator(X_train_normalized, y_train_normalized),\n",
    "                          steps_per_epoch=len(X_train_normalized) // batch_size,\n",
    "                          epochs=100,\n",
    "                          validation_data=(X_val_normalized, y_val_normalized),\n",
    "                          callbacks=[model_checkpoint, early_stopping, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea23bda",
   "metadata": {},
   "source": [
    "# Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ab17c76f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Serving 'best_model.h5' at http://localhost:8080\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "('localhost', 8080)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Network visualization\n",
    "netron.start('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "f8c40449",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_graphs(history, 'loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "1270c081",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 131s 7s/step - loss: 0.0458\n",
      "3/3 [==============================] - 19s 6s/step - loss: 0.0479\n",
      "3/3 [==============================] - 21s 6s/step - loss: 0.0491\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train</th>\n",
       "      <th>validation</th>\n",
       "      <th>test</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.045805</td>\n",
       "      <td>0.047926</td>\n",
       "      <td>0.049091</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      train  validation      test\n",
       "0  0.045805    0.047926  0.049091"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Train loss\n",
    "train_loss = autoencoder.evaluate(X_train_normalized, y_train_normalized, verbose=1)\n",
    "\n",
    "#Validation loss\n",
    "val_loss = autoencoder.evaluate(X_val_normalized, y_val_normalized, verbose=1)\n",
    "\n",
    "#Test loss\n",
    "test_loss = autoencoder.evaluate(X_test_normalized, y_test_normalized, verbose=1)\n",
    "\n",
    "results = pd.DataFrame([[train_loss, val_loss, test_loss]],\n",
    "            columns = ['train', 'validation', 'test'])\n",
    "results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "283a25b2",
   "metadata": {},
   "source": [
    "# Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "8a541305",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder=load_model('best_model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "e1704b6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 11s 3s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c2bc6290",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pred = get_audio_predictions(predictions[2], phase_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "541a5f85",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('audio_pred.wav', audio_pred, samplerate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "4f2e956a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('audio_noisy.wav', stft_to_audio(X_test[2], phase_test[2], hop_length_fft=304), samplerate=sr)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
