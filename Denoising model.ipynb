{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "18528fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c43fb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_audio(audio, max_duration=15, sample_rate=16000):\n",
    "    \"\"\"This function take an audio and padd that audio with zeros\"\"\"\n",
    "    \n",
    "    max_length = max_duration * sample_rate\n",
    "    padding_needed = max_length - len(audio)\n",
    "    pad_left = padding_needed // 2\n",
    "    pad_right = padding_needed - pad_left\n",
    "    \n",
    "    return np.pad(audio, (pad_left, pad_right), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d6fec962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audio(original_audio_path, noise_audio_path, sample_rate=16000):\n",
    "    \"\"\"This function take an original audio path and noise audio path and mix it together\"\"\"\n",
    "    \n",
    "    # Load the original audio\n",
    "    original_audio, sr = librosa.load(original_audio_path, sr=sample_rate)\n",
    "    \n",
    "    #Padd original audio\n",
    "    original_audio = padd_audio(original_audio, sample_rate=sample_rate)\n",
    "    \n",
    "    # Load the noise audio\n",
    "    noise_audio, sr_noise = librosa.load(noise_audio_path, sr=sample_rate)\n",
    "    \n",
    "    # Repeat the noise audio\n",
    "    noise_audio = np.tile(noise_audio, int(np.ceil(len(original_audio) / len(noise_audio))))\n",
    "\n",
    "    # Trim the repeated noise audio to match the length of the original audio\n",
    "    noise_audio = noise_audio[:len(original_audio)]\n",
    "    \n",
    "    return original_audio + noise_audio/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "66387d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_audio(original_audio_path, sample_rate=16000):\n",
    "    \"\"\"This function take an original audio path and return padded audio\"\"\"\n",
    "    \n",
    "    # Load the original audio\n",
    "    original_audio, sr = librosa.load(original_audio_path, sr=sample_rate)\n",
    "    \n",
    "    #Padd original audio\n",
    "    return padd_audio(original_audio, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "59bfacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000  # Sampling rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b89d2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randmly chosen noise for each audio\n",
    "def combine_audio_with_noise(original_audio_dir, noise_audio_dir):\n",
    "    combination_dict = {}\n",
    "    noise_audios = os.listdir(noise_audio_dir)\n",
    "    original_audios = os.listdir(original_audio_dir)\n",
    "    \n",
    "    for original_audio in original_audios:\n",
    "        noise_audio = np.random.choice(noise_audios)\n",
    "        combination_dict[os.path.join(original_audio_dir, original_audio)] = os.path.join(noise_audio_dir, noise_audio)\n",
    "        \n",
    "    return combination_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1fcecf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_stft(audio, n_fft=1199, hop_length_fft=300):\n",
    "    # STFT transformation\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "\n",
    "    # Extract magnitude and phase\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    # Convert magnitude to dB\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(stftaudio_magnitude, ref=np.max)\n",
    "    \n",
    "    return stftaudio_magnitude_db, stftaudio_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "21166314",
   "metadata": {},
   "outputs": [],
   "source": [
    "#audio_to_stft(sound1)[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "08cda225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_audio(stftaudio_magnitude_db, stftaudio_phase, hop_length_fft=300):\n",
    "# Convert dB back to amplitude\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # Reconstruct the STFT complex matrix\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "\n",
    "    # Inverse STFT to get back the audio signal\n",
    "    audio_reconstruct = librosa.istft(audio_reverse_stft, hop_length=hop_length_fft)\n",
    "\n",
    "    return audio_reconstruct / np.max(np.abs(audio_reconstruct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "861a3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of normalization function using global min and max values\n",
    "def normalize(stft, global_min, global_max):\n",
    "    return (stft - global_min) / (global_max - global_min)\n",
    "\n",
    "# Example of denormalization function using global min and max values\n",
    "def denormalize(normalized_stft, global_min, global_max):\n",
    "    return normalized_stft * (global_max - global_min) + global_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cabcf8",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "7f92181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_noise_pairs = combine_audio_with_noise(os.path.join(os.getcwd(), 'Dataset'), os.path.join(os.getcwd(), 'Noise'))\n",
    "\n",
    "#Getting all the noisy and clean audio matrices\n",
    "noisy_audios = np.zeros(len(audio_noise_pairs), dtype=object)\n",
    "clean_audios = np.zeros(len(audio_noise_pairs), dtype=object)\n",
    "\n",
    "for index, (audio_dir, noise_dir) in enumerate(audio_noise_pairs.items()):\n",
    "    noisy_audios[index] = mix_audio(audio_dir, noise_dir, sample_rate=16000)\n",
    "    clean_audios[index] = get_clean_audio(audio_dir, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1b5bbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting STFT data for learning process\n",
    "noisy_audios_stft = [audio_to_stft(audio)[0] for audio in noisy_audios]\n",
    "noisy_audios_stft_phase = [audio_to_stft(audio)[1] for audio in noisy_audios]\n",
    "clean_audios_stft = [audio_to_stft(audio)[0] for audio in clean_audios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "4e2c3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training and test set\n",
    "split_ratio = 0.8\n",
    "split_index = int(len(noisy_audios_stft) * split_ratio)\n",
    "\n",
    "X_train = noisy_audios_stft[:split_index]\n",
    "X_test = noisy_audios_stft[split_index:]\n",
    "\n",
    "y_train = clean_audios_stft[:split_index]\n",
    "y_test = clean_audios_stft[split_index:]\n",
    "\n",
    "phase_training = noisy_audios_stft_phase[:split_index]\n",
    "phase_test = noisy_audios_stft_phase[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "717c6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the global min and max values from both the noisy and clean STFT data\n",
    "global_min = min(np.min(X_train), np.min(y_train))\n",
    "global_max = max(np.max(X_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "7bbecd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data based on the data from training set\n",
    "X_train_normalized = normalize(X_train, global_min, global_max)\n",
    "X_test_normalized = normalize(X_test, global_min, global_max)\n",
    "y_train_normalized = normalize(y_train, global_min, global_max)\n",
    "y_test_normalized = normalize(y_test, global_min, global_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1ba886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data to tensors: sample x dimensions(n x n) x channel(1)\n",
    "X_train_normalized = X_train_normalized[..., np.newaxis]\n",
    "X_test_normalized = X_test_normalized[..., np.newaxis]\n",
    "y_train_normalized = y_train_normalized[..., np.newaxis]\n",
    "y_test_normalized = y_test_normalized[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e240f8d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savez('input_data.npz', array1=X_train_normalized, array2=X_test_normalized, array3=y_train_normalized, array4=y_test_normalized, array5=phase_training, array6=phase_test, array7=global_min, array8=global_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3e4fad93",
   "metadata": {},
   "source": [
    "# Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "69a1a025",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.load('input_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3a4103cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_normalized = data['array1']\n",
    "X_test_normalized = data['array2']\n",
    "y_train_normalized = data['array3']\n",
    "y_test_normalized = data['array4']\n",
    "phase_training = data['array5']\n",
    "phase_test = data['array6']\n",
    "global_min = data['array7']\n",
    "global_max = data['array8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "347cd5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sound1 = mix_audio(os.path.join(os.getcwd(), 'Dataset', '89-218-0001.flac'), os.path.join(os.getcwd(), 'Noise', '5-202898-A-10.wav'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6dd49dba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, y, batch_size=16, epochs=10):\n",
    "    assert len(X) == len(y), \"The length of X and y must be the same\"\n",
    "    \n",
    "    # Iterate through each epoch\n",
    "    for epoch in range(epochs):\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        \n",
    "        for start in range(0, len(X), batch_size):\n",
    "            end = min(start + batch_size, len(X))\n",
    "            batch_X = X_shuffled[start:end]\n",
    "            batch_y = y_shuffled[start:end]\n",
    "            \n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80f88407",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_2 (InputLayer)        [(None, 600, 800, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_4 (Conv2D)           (None, 600, 800, 32)      320       \n",
      "                                                                 \n",
      " max_pooling2d_1 (MaxPooling  (None, 300, 400, 32)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_5 (Conv2D)           (None, 300, 400, 64)      18496     \n",
      "                                                                 \n",
      " up_sampling2d_1 (UpSampling  (None, 600, 800, 64)     0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 600, 800, 32)      18464     \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 600, 800, 1)       289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 37,569\n",
      "Trainable params: 37,569\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      " 16/251 [>.............................] - ETA: 1:07:02 - loss: 0.0872"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, BatchNormalization, MaxPooling2D, Input\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "def encoder(inputs): #(201, 1201, 1)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "    \n",
    "    encoded = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    return encoded\n",
    "\n",
    "# Decoder\n",
    "def decoder(encoded):\n",
    "    x = UpSampling2D((2, 2))(encoded)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)  # Single channel output\n",
    "    return decoded\n",
    "\n",
    "# Input shape\n",
    "input_shape = (600, 800, 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Build the autoencoder\n",
    "encoded = encoder(inputs)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Summary of the model\n",
    "autoencoder.summary()\n",
    "\n",
    "batch_size = 16\n",
    "# Fit the model (example)\n",
    "autoencoder.fit(generator(X_train_normalized, y_train_normalized),\n",
    "                          steps_per_epoch=len(X_train_normalized) // batch_size,\n",
    "                          epochs=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db2c49ca",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
