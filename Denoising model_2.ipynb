{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "18528fdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import librosa\n",
    "import librosa.display\n",
    "import numpy as np\n",
    "import soundfile as sf\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "c43fb9a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def padd_audio(audio, max_duration=5, sample_rate=16000):\n",
    "    \"\"\"This function take an audio and padd that audio with zeros\"\"\"\n",
    "    \n",
    "    max_length = max_duration * sample_rate\n",
    "    padding_needed = max_length - len(audio)\n",
    "    pad_left = padding_needed // 2\n",
    "    pad_right = padding_needed - pad_left\n",
    "    \n",
    "    return np.pad(audio, (pad_left, pad_right), 'constant')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d6fec962",
   "metadata": {},
   "outputs": [],
   "source": [
    "def mix_audio(original_audio_path, noise_audio_path, sample_rate=16000):\n",
    "    \"\"\"This function take an original audio path and noise audio path and mix it together\"\"\"\n",
    "    \n",
    "    # Load the original audio\n",
    "    original_audio, sr = librosa.load(original_audio_path, sr=sample_rate)\n",
    "    \n",
    "    #Padd original audio\n",
    "    original_audio = padd_audio(original_audio, sample_rate=sample_rate)\n",
    "    \n",
    "    # Load the noise audio\n",
    "    noise_audio, sr_noise = librosa.load(noise_audio_path, sr=sample_rate)\n",
    "    \n",
    "    # Repeat the noise audio\n",
    "    noise_audio = np.tile(noise_audio, int(np.ceil(len(original_audio) / len(noise_audio))))\n",
    "\n",
    "    # Trim the repeated noise audio to match the length of the original audio\n",
    "    noise_audio = noise_audio[:len(original_audio)]\n",
    "    \n",
    "    return original_audio + noise_audio/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "66387d32",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_clean_audio(original_audio_path, sample_rate=16000):\n",
    "    \"\"\"This function take an original audio path and return padded audio\"\"\"\n",
    "    \n",
    "    # Load the original audio\n",
    "    original_audio, sr = librosa.load(original_audio_path, sr=sample_rate)\n",
    "    \n",
    "    #Padd original audio\n",
    "    return padd_audio(original_audio, sample_rate=sample_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "59bfacac",
   "metadata": {},
   "outputs": [],
   "source": [
    "sr = 16000  # Sampling rate   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "b89d2956",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randmly chosen noise for each audio\n",
    "def combine_audio_with_noise(original_audio_dir, noise_audio_dir):\n",
    "    combination_dict = {}\n",
    "    noise_audios = os.listdir(noise_audio_dir)\n",
    "    original_audios = os.listdir(original_audio_dir)\n",
    "    \n",
    "    for original_audio in original_audios:\n",
    "        noise_audio = np.random.choice(noise_audios)\n",
    "        combination_dict[os.path.join(original_audio_dir, original_audio)] = os.path.join(noise_audio_dir, noise_audio)\n",
    "        \n",
    "    return combination_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "1fcecf7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def audio_to_stft(audio, n_fft=1199, hop_length_fft=304):\n",
    "    # STFT transformation\n",
    "    stftaudio = librosa.stft(audio, n_fft=n_fft, hop_length=hop_length_fft)\n",
    "\n",
    "    # Extract magnitude and phase\n",
    "    stftaudio_magnitude, stftaudio_phase = librosa.magphase(stftaudio)\n",
    "\n",
    "    # Convert magnitude to dB\n",
    "    stftaudio_magnitude_db = librosa.amplitude_to_db(stftaudio_magnitude, ref=np.max)\n",
    "    \n",
    "    return stftaudio_magnitude_db, stftaudio_phase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "08cda225",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stft_to_audio(stftaudio_magnitude_db, stftaudio_phase, hop_length_fft=304):\n",
    "# Convert dB back to amplitude\n",
    "    stftaudio_magnitude_rev = librosa.db_to_amplitude(stftaudio_magnitude_db, ref=1.0)\n",
    "\n",
    "    # Reconstruct the STFT complex matrix\n",
    "    audio_reverse_stft = stftaudio_magnitude_rev * stftaudio_phase\n",
    "\n",
    "    # Inverse STFT to get back the audio signal\n",
    "    audio_reconstruct = librosa.istft(audio_reverse_stft, hop_length=hop_length_fft)\n",
    "\n",
    "    return audio_reconstruct / np.max(np.abs(audio_reconstruct))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "id": "861a3435",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of normalization function using global min and max values\n",
    "def normalize(stft, global_min, global_max):\n",
    "    return (stft - global_min) / (global_max - global_min)\n",
    "\n",
    "# Example of denormalization function using global min and max values\n",
    "def denormalize(normalized_stft, global_min, global_max):\n",
    "    return normalized_stft * (global_max - global_min) + global_min"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83cabcf8",
   "metadata": {},
   "source": [
    "# Preprocessing the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "7f92181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_noise_pairs = combine_audio_with_noise(os.path.join(os.getcwd(), 'Dataset'), os.path.join(os.getcwd(), 'Noise'))\n",
    "\n",
    "#Getting all the noisy and clean audio matrices\n",
    "noisy_audios = np.zeros(len(audio_noise_pairs), dtype=object)\n",
    "clean_audios = np.zeros(len(audio_noise_pairs), dtype=object)\n",
    "\n",
    "for index, (audio_dir, noise_dir) in enumerate(audio_noise_pairs.items()):\n",
    "    noisy_audios[index] = mix_audio(audio_dir, noise_dir, sample_rate=16000)\n",
    "    clean_audios[index] = get_clean_audio(audio_dir, sample_rate=16000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "1b5bbe56",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting STFT data for learning process\n",
    "noisy_audios_stft = [audio_to_stft(audio)[0] for audio in noisy_audios]\n",
    "noisy_audios_stft_phase = [audio_to_stft(audio)[1] for audio in noisy_audios]\n",
    "clean_audios_stft = [audio_to_stft(audio)[0] for audio in clean_audios]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "4e2c3ab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting the data for training and test set\n",
    "split_ratio = 0.9\n",
    "split_index = int(len(noisy_audios_stft) * split_ratio)\n",
    "\n",
    "X_train = noisy_audios_stft[:split_index]\n",
    "X_test = noisy_audios_stft[split_index:]\n",
    "\n",
    "y_train = clean_audios_stft[:split_index]\n",
    "y_test = clean_audios_stft[split_index:]\n",
    "\n",
    "phase_training = noisy_audios_stft_phase[:split_index]\n",
    "phase_test = noisy_audios_stft_phase[split_index:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "717c6024",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find the global min and max values from both the noisy and clean STFT data\n",
    "global_min = min(np.min(X_train), np.min(y_train))\n",
    "global_max = max(np.max(X_train), np.max(y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "7bbecd2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Normalize data based on the data from training set\n",
    "X_train_normalized = normalize(X_train, global_min, global_max)\n",
    "X_test_normalized = normalize(X_test, global_min, global_max)\n",
    "y_train_normalized = normalize(y_train, global_min, global_max)\n",
    "y_test_normalized = normalize(y_test, global_min, global_max)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1ba886f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Transform data to tensors: sample x dimensions(n x n) x channel(1)\n",
    "X_train_normalized = X_train_normalized[..., np.newaxis]\n",
    "X_test_normalized = X_test_normalized[..., np.newaxis]\n",
    "y_train_normalized = y_train_normalized[..., np.newaxis]\n",
    "y_test_normalized = y_test_normalized[..., np.newaxis]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ee3490f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.savez('input_data.npz', array1=X_train_normalized, array2=X_test_normalized, array3=y_train_normalized, array4=y_test_normalized, array5=phase_training, array6=phase_test, array7=global_min, array8=global_max)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fb963993",
   "metadata": {},
   "source": [
    "# Load the preprocessed data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "d4935a2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = np.load('input_data.npz')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "f6a8ec2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#X_train_normalized = data['array1']\n",
    "#X_test_normalized = data['array2']\n",
    "#y_train_normalized = data['array3']\n",
    "#y_test_normalized = data['array4']\n",
    "#phase_training = data['array5']\n",
    "#phase_test = data['array6']\n",
    "#global_min = data['array7']\n",
    "#global_max = data['array8']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "770cc9eb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(X, y, batch_size=16, epochs=20):\n",
    "    assert len(X) == len(y), \"The length of X and y must be the same\"\n",
    "    \n",
    "    # Iterate through each epoch\n",
    "    for epoch in range(epochs):\n",
    "        indices = np.arange(len(X))\n",
    "        np.random.shuffle(indices)\n",
    "        X_shuffled = X[indices]\n",
    "        y_shuffled = y[indices]\n",
    "        \n",
    "        for start in range(0, len(X), batch_size):\n",
    "            end = min(start + batch_size, len(X))\n",
    "            batch_X = X_shuffled[start:end]\n",
    "            batch_y = y_shuffled[start:end]\n",
    "            \n",
    "            yield batch_X, batch_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "4cf55b97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_10\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_11 (InputLayer)       [(None, 600, 264, 1)]     0         \n",
      "                                                                 \n",
      " conv2d_68 (Conv2D)          (None, 600, 264, 32)      320       \n",
      "                                                                 \n",
      " batch_normalization_44 (Bat  (None, 600, 264, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_24 (MaxPoolin  (None, 300, 132, 32)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_69 (Conv2D)          (None, 300, 132, 64)      18496     \n",
      "                                                                 \n",
      " batch_normalization_45 (Bat  (None, 300, 132, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_25 (MaxPoolin  (None, 150, 66, 64)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_70 (Conv2D)          (None, 150, 66, 128)      73856     \n",
      "                                                                 \n",
      " batch_normalization_46 (Bat  (None, 150, 66, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " max_pooling2d_26 (MaxPoolin  (None, 75, 33, 128)      0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_71 (Conv2D)          (None, 75, 33, 256)       295168    \n",
      "                                                                 \n",
      " up_sampling2d_24 (UpSamplin  (None, 150, 66, 256)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_72 (Conv2D)          (None, 150, 66, 128)      295040    \n",
      "                                                                 \n",
      " batch_normalization_47 (Bat  (None, 150, 66, 128)     512       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_25 (UpSamplin  (None, 300, 132, 128)    0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_73 (Conv2D)          (None, 300, 132, 64)      73792     \n",
      "                                                                 \n",
      " batch_normalization_48 (Bat  (None, 300, 132, 64)     256       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " up_sampling2d_26 (UpSamplin  (None, 600, 264, 64)     0         \n",
      " g2D)                                                            \n",
      "                                                                 \n",
      " conv2d_74 (Conv2D)          (None, 600, 264, 32)      18464     \n",
      "                                                                 \n",
      " batch_normalization_49 (Bat  (None, 600, 264, 32)     128       \n",
      " chNormalization)                                                \n",
      "                                                                 \n",
      " conv2d_75 (Conv2D)          (None, 600, 264, 1)       289       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 777,217\n",
      "Trainable params: 776,321\n",
      "Non-trainable params: 896\n",
      "_________________________________________________________________\n",
      "Epoch 1/20\n",
      "39/39 [==============================] - 466s 12s/step - loss: 0.0691\n",
      "Epoch 2/20\n",
      "39/39 [==============================] - 468s 12s/step - loss: 0.0321\n",
      "Epoch 3/20\n",
      "39/39 [==============================] - 454s 12s/step - loss: 0.0238\n",
      "Epoch 4/20\n",
      "39/39 [==============================] - 458s 12s/step - loss: 0.0206\n",
      "Epoch 5/20\n",
      "39/39 [==============================] - 459s 12s/step - loss: 0.0190\n",
      "Epoch 6/20\n",
      "39/39 [==============================] - 463s 12s/step - loss: 0.0231\n",
      "Epoch 7/20\n",
      "39/39 [==============================] - 472s 12s/step - loss: 0.0232\n",
      "Epoch 8/20\n",
      "39/39 [==============================] - 471s 12s/step - loss: 0.0218\n",
      "Epoch 9/20\n",
      "39/39 [==============================] - 467s 12s/step - loss: 0.0194\n",
      "Epoch 10/20\n",
      "39/39 [==============================] - 468s 12s/step - loss: 0.0191\n",
      "Epoch 11/20\n",
      "39/39 [==============================] - 474s 12s/step - loss: 0.0181\n",
      "Epoch 12/20\n",
      "39/39 [==============================] - 471s 12s/step - loss: 0.0244\n",
      "Epoch 13/20\n",
      "39/39 [==============================] - 473s 12s/step - loss: 0.0182\n",
      "Epoch 14/20\n",
      "39/39 [==============================] - 480s 12s/step - loss: 0.0198\n",
      "Epoch 15/20\n",
      "39/39 [==============================] - 472s 12s/step - loss: 0.0179\n",
      "Epoch 16/20\n",
      "39/39 [==============================] - 473s 12s/step - loss: 0.0171\n",
      "Epoch 17/20\n",
      "39/39 [==============================] - 478s 12s/step - loss: 0.0180\n",
      "Epoch 18/20\n",
      "39/39 [==============================] - 469s 12s/step - loss: 0.0170\n",
      "Epoch 19/20\n",
      "39/39 [==============================] - 467s 12s/step - loss: 0.0169\n",
      "Epoch 20/20\n",
      "39/39 [==============================] - 470s 12s/step - loss: 0.0164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x1afb10adb10>"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.layers import Conv2D, UpSampling2D, BatchNormalization, MaxPooling2D, Input, Dropout\n",
    "from tensorflow.keras.models import Model\n",
    "\n",
    "# Encoder\n",
    "def encoder(inputs):\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(inputs)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "    x = MaxPooling2D((2, 2))(x)\n",
    "\n",
    "    encoded = Conv2D(256, (3, 3), activation='relu', padding='same')(x)\n",
    "    return encoded\n",
    "\n",
    "# Decoder\n",
    "def decoder(encoded):\n",
    "    x = UpSampling2D((2, 2))(encoded)\n",
    "    x = Conv2D(128, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(64, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    x = UpSampling2D((2, 2))(x)\n",
    "    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n",
    "    x = BatchNormalization()(x)\n",
    "\n",
    "    decoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)  # Single channel output\n",
    "    return decoded\n",
    "\n",
    "# Input shape\n",
    "input_shape = (600, 264, 1)\n",
    "inputs = Input(shape=input_shape)\n",
    "\n",
    "# Build the autoencoder\n",
    "encoded = encoder(inputs)\n",
    "decoded = decoder(encoded)\n",
    "\n",
    "autoencoder = Model(inputs, decoded)\n",
    "autoencoder.compile(optimizer='adam', loss='mse')\n",
    "\n",
    "# Summary of the model\n",
    "autoencoder.summary()\n",
    "\n",
    "batch_size = 16\n",
    "# Fit the model (example)\n",
    "autoencoder.fit(generator(X_train_normalized, y_train_normalized),\n",
    "                steps_per_epoch=len(X_train_normalized) // batch_size,\n",
    "                epochs=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "2b1a0b31",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_audio_predictions(output_prediction, phase, global_min=global_min, global_max=global_max):\n",
    "    prediction = denormalize(output_prediction.squeeze(), global_min, global_max)\n",
    "    audio_prediction = stft_to_audio(prediction, phase, hop_length_fft=304)\n",
    "    return audio_prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "f6030c00",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3/3 [==============================] - 14s 3s/step\n"
     ]
    }
   ],
   "source": [
    "predictions = autoencoder.predict(X_test_normalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "14f7c1b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "audio_pred = get_audio_predictions(predictions[2], phase_test[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "72d08868",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('audio_pred.wav', audio_pred, samplerate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "be4db2c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "sf.write('audio_noisy.wav', stft_to_audio(X_test[2], phase_test[2], hop_length_fft=304), samplerate=sr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "7cb1222b",
   "metadata": {},
   "outputs": [],
   "source": [
    "autoencoder.save('autoencoder_model.h5')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
